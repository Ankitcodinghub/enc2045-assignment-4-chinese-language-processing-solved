# enc2045-assignment-4-chinese-language-processing-solved
**TO GET THIS SOLUTION VISIT:** [ENC2045 Assignment 4-Chinese Language Processing Solved](https://www.ankitcodinghub.com/product/enc2045-assignment-4-chinese-language-processing-solved/)


---

ğŸ“© **If you need this solution or have special requests:** **Email:** ankitcoding@gmail.com  
ğŸ“± **WhatsApp:** +1 419 877 7882  
ğŸ“„ **Get a quote instantly using this form:** [Ask Homework Questions](https://www.ankitcodinghub.com/services/ask-homework-questions/)

*We deliver fast, professional, and affordable academic help.*

---

<h2>Description</h2>



<div class="kk-star-ratings kksr-auto kksr-align-center kksr-valign-top" data-payload="{&quot;align&quot;:&quot;center&quot;,&quot;id&quot;:&quot;90851&quot;,&quot;slug&quot;:&quot;default&quot;,&quot;valign&quot;:&quot;top&quot;,&quot;ignore&quot;:&quot;&quot;,&quot;reference&quot;:&quot;auto&quot;,&quot;class&quot;:&quot;&quot;,&quot;count&quot;:&quot;5&quot;,&quot;legendonly&quot;:&quot;&quot;,&quot;readonly&quot;:&quot;&quot;,&quot;score&quot;:&quot;5&quot;,&quot;starsonly&quot;:&quot;&quot;,&quot;best&quot;:&quot;5&quot;,&quot;gap&quot;:&quot;4&quot;,&quot;greet&quot;:&quot;Rate this product&quot;,&quot;legend&quot;:&quot;5\/5 - (5 votes)&quot;,&quot;size&quot;:&quot;24&quot;,&quot;title&quot;:&quot;ENC2045 Assignment 4-Chinese Language Processing&nbsp;Solved&quot;,&quot;width&quot;:&quot;138&quot;,&quot;_legend&quot;:&quot;{score}\/{best} - ({count} {votes})&quot;,&quot;font_factor&quot;:&quot;1.25&quot;}">

<div class="kksr-stars">

<div class="kksr-stars-inactive">
            <div class="kksr-star" data-star="1" style="padding-right: 4px">


<div class="kksr-icon" style="width: 24px; height: 24px;"></div>
        </div>
            <div class="kksr-star" data-star="2" style="padding-right: 4px">


<div class="kksr-icon" style="width: 24px; height: 24px;"></div>
        </div>
            <div class="kksr-star" data-star="3" style="padding-right: 4px">


<div class="kksr-icon" style="width: 24px; height: 24px;"></div>
        </div>
            <div class="kksr-star" data-star="4" style="padding-right: 4px">


<div class="kksr-icon" style="width: 24px; height: 24px;"></div>
        </div>
            <div class="kksr-star" data-star="5" style="padding-right: 4px">


<div class="kksr-icon" style="width: 24px; height: 24px;"></div>
        </div>
    </div>

<div class="kksr-stars-active" style="width: 138px;">
            <div class="kksr-star" style="padding-right: 4px">


<div class="kksr-icon" style="width: 24px; height: 24px;"></div>
        </div>
            <div class="kksr-star" style="padding-right: 4px">


<div class="kksr-icon" style="width: 24px; height: 24px;"></div>
        </div>
            <div class="kksr-star" style="padding-right: 4px">


<div class="kksr-icon" style="width: 24px; height: 24px;"></div>
        </div>
            <div class="kksr-star" style="padding-right: 4px">


<div class="kksr-icon" style="width: 24px; height: 24px;"></div>
        </div>
            <div class="kksr-star" style="padding-right: 4px">


<div class="kksr-icon" style="width: 24px; height: 24px;"></div>
        </div>
    </div>
</div>


<div class="kksr-legend" style="font-size: 19.2px;">
            5/5 - (5 votes)    </div>
    </div>
<div class="page" title="Page 1">
<div class="section">
<div class="section">
<div class="section">
<div class="layoutArea">
<div class="column">
4. Assignment IV: Chinese Language Processing

The csv le dcard-top100.csv includes top 100 posts from Dcard, which a on-line discussion forum for school life in Taiwan. The texts are in the content column.

Please preprocess the data by:

removing symbols, punctuations, emoticons or other non-linguistic symbols

removing stopwords (Please use the stopword list provided in demo_data/stopwords/tomlinNTUB-chinese-stopwords.txt) performing word segmentation on the corpus using ckip-transformer

creating a word frequency list of this tiny corpus

including only word tokens which have at least two characters in the frequency list

ï± Warning

Please note that the preprocessing steps are important. Removal of characters from texts may have a lot to do with the word

segmentation performance.

LEMMA FREQ 0 çœŸçš„ 115 1 æ²’æœ‰ 92 2 è¦ºå¾— 90 3 çŸ¥é“ 70 4 çœ‹åˆ° 67 5 ç¾åœ¨ 63 6 å–œæ­¡ 56 7 æœ‹å‹ 54 8 å…¶å¯¦ 52 9 ä¸€ç›´ 52

10 ä¸æœƒ 51 11 ç™¼ç¾ 43 12 ç”·å‹ 42 13 ä¸€ä¸‹ 41 14 å·²ç¶“ 41 15 å¾ˆå¤š 40 16 æ™‚é–“ 40 17 å·¥ä½œ 40 18 åˆ†äº« 39 19 æ„Ÿè¦º 39 20 ä¸€èµ· 38

4.2. Question 2

Use ckip-transformer to extract all named entities and create a frequency list of the named entities.

In particular, please identify named entities of organizations (ORG) and geographical names (GPE) and provide their frequencies in the Dcard Corpus.

</div>
<div class="column">
ï€º Contents

4.1. Question 1 4.2. Question 2 4.3. Question 3 4.4. Question 4

</div>
</div>
</div>
<div class="section">
<div class="layoutArea">
<div class="column">
Print to PDF

</div>
</div>
</div>
</div>
<div class="layoutArea">
<div class="column">
https://alvinntnu.github.io/NTNU_ENC2045_LECTURES/exercise/4-chinese-nlp.html 1/4

</div>
</div>
</div>
</div>
<div class="page" title="Page 2">
<div class="section">
<div class="layoutArea">
<div class="column">
3/25/2021 4. Assignment IV: Chinese Language Processing â€” ENC2045 Computational Linguistics

</div>
</div>
<div class="section">
<div class="layoutArea">
<div class="column">
LEMMA FREQ 0 å°ç£ 23 1 æ—¥æœ¬ 18 2 å°å— 7 3å°6 4 è‹±åœ‹ 5 5 å°ä¸­ 4 6 æ²–ç¹© 4 7 éŸ“åœ‹ 4 8 è–åœ­ 4 9 å°åŒ— 3

10 å¾·åœ‹ 3 11 å°å¤§ 2 12 æœå…‹å¤§å­¸ 2 13 æ±äº¬ 2 14 SHINee 2 15 ç¾ 2 16 æ¿æ©‹ 2 17 æ­¦æ— 2 18 å·´é» 2 19 é¹¿æ¸¯ 2 20 Celine 2

4.3. Question 3

In this exercise, please work with spacy for Chinese processing. (Use the model zh_core_web_trf) Please process the same Dcard Corpus (from the csv le) by:

performing the word tokenization

identifying all nouns and verbs (i.e., words whose tags start with N or V) identifying all words with at least two characters

removing all words that contain alphabets or digits

removing all words that are included in the stopword_list (cf. Question 1)

Based on the above text-preprocessing criteria, your goal is to create a word frequency list and visualize the result in a Word Cloud.

ïš Note

spacy uses the jieba for Chinese word segmentation. There may be more tagging errors. In the expected results presented below, I did

not use any self-dened dictionary. For this exercise, please ignore any tagging errors out of the module for the moment.

ïƒ« Tip

Please check the module wordcloud for the visualization.

</div>
</div>
</div>
<div class="layoutArea">
<div class="column">
https://alvinntnu.github.io/NTNU_ENC2045_LECTURES/exercise/4-chinese-nlp.html 2/4

</div>
</div>
</div>
</div>
<div class="page" title="Page 3">
<div class="section">
<div class="layoutArea">
<div class="column">
3/25/2021 4. Assignment IV: Chinese Language Processing â€” ENC2045 Computational Linguistics

</div>
</div>
<div class="section">
<div class="layoutArea">
<div class="column">
N-V FREQ 0çŸ¥é“ 70 1çœ‹åˆ° 67 2æœ‹å‹ 55 3å–œæ­¡ 55 4åˆ†äº« 43 5ç”·å‹ 42 6æ²’æœ‰ 41 7å·¥ä½œ 40 8å¾ˆå¤š 39 9ç¬¬ä¸€ 38

10æ„Ÿè¦º 38 11æ™‚é–“ 37 12ç™¼ç¾ 36 13 == 36 14å¸Œæœ› 35 15æ„Ÿæƒ… 33 16ä»Šå¤© 33 17è›‹ç³• 32 18éƒ¨åˆ† 30 19å‡ºå» 30 20æƒ³è¦ 30

4.4. Question 4

Following Question 3, after you process each article with spacy, please extract all the subject + predicate word pairs from the corpus.

To simplify the task, please extract word token pairs whose dependency relation is nsubj, with the predicate being the head and subject being the

dependent.

Remove words that include alphabets and digits

</div>
</div>
</div>
<div class="layoutArea">
<div class="column">
https://alvinntnu.github.io/NTNU_ENC2045_LECTURES/exercise/4-chinese-nlp.html 3/4

</div>
</div>
</div>
</div>
<div class="page" title="Page 4">
<div class="section">
<div class="layoutArea">
<div class="column">
3/25/2021 4. Assignment IV: Chinese Language Processing â€” ENC2045 Computational Linguistics

</div>
</div>
<div class="section">
<div class="layoutArea">
<div class="column">
SUBJ-PRED FREQ 0 æˆ‘_å–œæ­¡ 21 1 ä»–_èªª 20 2 æˆ‘_æƒ³ 19 3 æˆ‘_è¦º 19 4 æˆ‘_çŸ¥é“ 16 5 æˆ‘_çœ‹ 14 6 æˆ‘_çœ‹åˆ° 11 7 æˆ‘_ç”¨ 10 8 æˆ‘_èªª 8 9 å¤§å®¶_å¥½ 8

10 æˆ‘_æ„› 8 11 æˆ‘_æœ‰ 7 12 ä½ _æœ‰ 7 13 æˆ‘_å» 6 14 ä»–_è¦º 6 15 æˆ‘_è¦ 6 16 æˆ‘_æ±ºå®š 6 17 å¥¹_èªª 6 18 æˆ‘_ç™¼ç¾ 5 19 æˆ‘_å• 5 20 æˆ‘_åœ¨ 5

</div>
</div>
</div>
</div>
</div>
